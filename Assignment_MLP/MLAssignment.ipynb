{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jj-h8-EeocN6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "112b7017-2cf7-4c4b-a8ba-35af87838b05"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from random import random\n",
        "from random import seed\n",
        "from math import exp\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "\n",
        "#DATA POINTS\n",
        "sampleNum = 200\n",
        "\n",
        "#FEATURES\n",
        "featureNum = 4\n",
        "\n",
        "#REDUNDENT\n",
        "redundantNum = 1\n",
        "\n",
        "#CLASSES\n",
        "classesNum = 2\n",
        "\n",
        "#READING Dataset\n",
        "X, y = make_classification(n_samples=sampleNum, n_features=featureNum, n_redundant=redundantNum, n_classes=classesNum)\n",
        "df = pd.DataFrame(X, columns=['feature1', 'feature2', 'feature3', 'feature4'])\n",
        "df['label'] = y\n",
        "df.to_csv(\"dataset1.csv\")\n",
        "df=pd.read_csv('dataset1.csv',index_col=0)\n",
        "\n",
        "\n",
        "#FUNCTION FOR TRANSFER\n",
        "def transferFun(activater):\n",
        "    return 1.0 / (1.0 + exp(-activater))\n",
        "\n",
        "\n",
        "#FUNCTION FOR TRANSFERING DEVRIVATIVE\n",
        "def transferDerivative(input):\n",
        "    return input * (1.0 - input)\n",
        "\n",
        "\n",
        "#PREDICTION FUNCTION\n",
        "def predicting(net, row):\n",
        "    otpt = forwardPropagate(net, row)\n",
        "    return otpt.index(max(otpt))\n",
        "\n",
        "#FUNCTION FOR ACTIVATION\n",
        "def activateFun(wt, inp):\n",
        "    activator=wt[-1]\n",
        "    for i in range(len(wt)-1):\n",
        "        activator+=wt[i]*inp[i]\n",
        "    return activator\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#NETWORK INITIALIZING\n",
        "def networkInitializing(inputNum, hiddenNum, outputNum):\n",
        "    net=list()\n",
        "    hiddenLayer = [{'weights':[random() for i in range(inputNum + 1)]} for i in range(hiddenNum)]\n",
        "    net.append(hiddenLayer)\n",
        "    outputLayer = [{'weights':[random() for i in range(hiddenNum + 1)]} for i in range(outputNum)]\n",
        "    net.append(outputLayer)\n",
        "    return net\n",
        "\n",
        "\n",
        "\n",
        "#FUNCTION FOR BACKWARD PROPOGATION\n",
        "def backwardPropagate(net, expted):\n",
        "    for i in reversed(range(len(net))):\n",
        "        lyr = net[i]\n",
        "        err = list()\n",
        "        if i != len(net)-1:\n",
        "            for j in range(len(lyr)):\n",
        "                error = 0.0\n",
        "                for neur in net[i + 1]:\n",
        "                    error += (neur['weights'][j] * neur['delta'])\n",
        "                err.append(error)\n",
        "        else:\n",
        "            for j in range(len(lyr)):\n",
        "                neur = lyr[j]\n",
        "                err.append(expted[j] - neur['output'])\n",
        "        for j in range(len(lyr)):\n",
        "            neur = lyr[j]\n",
        "            neur['delta'] = err[j] * transferDerivative(neur['output'])\n",
        "\n",
        "\n",
        "\n",
        "#FORWARD PORPOGATION\n",
        "def forwardPropagate(net,data):\n",
        "    rawInp=data\n",
        "    for i in net:\n",
        "        newRaw=[]\n",
        "        for j in i:\n",
        "            activater=activateFun(j['weights'], rawInp)\n",
        "            j['output']=transferFun(activater)\n",
        "            newRaw.append(j['output'])\n",
        "        rawInp=newRaw\n",
        "    return rawInp\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#FUNCTION FOR TRAINING THE NETWORK\n",
        "def trainNetworkFun(net, training, l_rate, epochNum, outputNum):\n",
        "    for epoch in range(epochNum):\n",
        "        sum_err = 0\n",
        "        for row in training:\n",
        "            otpt = forwardPropagate(net, row)\n",
        "            expted = [0 for i in range(outputNum)]\n",
        "            expted[int(row[-1])] = 1\n",
        "            sum_err += sum([(expted[i]-otpt[i])**2 for i in range(len(expted))])\n",
        "            backwardPropagate(net, expted)\n",
        "            updatingWeights(net, row, l_rate)\n",
        "        print('Loop=%d, learn_rate=%.3f, Error=%.3f' % (epoch, l_rate, sum_err))\n",
        "\n",
        "\n",
        "\n",
        "#FUNCTIONING FOR UPDATING WEIGHTS\n",
        "def updatingWeights(net, row, l_rate):\n",
        "    for i in range(len(net)):\n",
        "        inp=row[:-1]\n",
        "        if i!=0:\n",
        "            inp=[neur['output'] for neur in net[i-1]]\n",
        "        for neur in net[i]:\n",
        "            for j in range(len(inp)):\n",
        "                neur['weights'][j]+=l_rate*neur['delta']*inp[j]\n",
        "            neur['weights'][-1]+=l_rate*neur['delta']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#ARRAY IN DATASET\n",
        "dataset=np.array(df[:])\n",
        "dataset\n",
        "\n",
        "\n",
        "#SETTING INPIT AND OUTPUT\n",
        "inputNum = len(dataset[0]) - 1\n",
        "outputNum = len(set([row[-1] for row in dataset]))\n",
        "print(inputNum,outputNum)\n",
        "\n",
        "\n",
        "#SPLIT DATASET\n",
        "trainDatasetVar=dataset[:150]\n",
        "testDatasetVar=dataset[150:]\n",
        "\n",
        "\n",
        "\n",
        "#DATASET INTO NET\n",
        "net=networkInitializing(inputNum,1,outputNum)\n",
        "trainNetworkFun(net, trainDatasetVar, 0.5, 100, outputNum)\n",
        "\n",
        "\n",
        "\n",
        "#WEIGHTS OF NETWORK\n",
        "for lyr in net:\n",
        "    print(lyr)\n",
        "\n",
        "\n",
        "\n",
        "#TESTING DATASET\n",
        "testSet=[]\n",
        "pred=[]\n",
        "for row in testDatasetVar:\n",
        "    prediction = predicting(net, row)\n",
        "    testSet.append(row[-1])\n",
        "    pred.append(prediction)\n",
        "print()\n",
        "print(\"TEST DATASET\")\n",
        "print(\"Confusion Matrix is: \",confusion_matrix(testSet,pred))\n",
        "print(\"Accuracy is: \",accuracy_score(testSet,pred))\n",
        "print(\"Precision is: \",precision_score(testSet, pred))\n",
        "print(\"recall is: \",recall_score(testSet, pred))\n",
        "\n",
        "\n",
        "\n",
        "#TRAINING DATASET\n",
        "trainSet=[]\n",
        "pred=[]\n",
        "for row in trainDatasetVar:\n",
        "    prediction = predicting(net, row)\n",
        "    trainSet.append(int(row[-1]))\n",
        "    pred.append(prediction)\n",
        "\n",
        "print()\n",
        "print(\"TRAIN DATASET\")\n",
        "print(\"Confusion Matrix is: \",confusion_matrix(trainSet,pred))\n",
        "print(\"Accuracy is: \",accuracy_score(trainSet,pred))\n",
        "print(\"Precision is: \",precision_score(trainSet, pred))\n",
        "print(\"recall is: \",recall_score(trainSet, pred))\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4 2\n",
            "Loop=0, learn_rate=0.500, Error=74.452\n",
            "Loop=1, learn_rate=0.500, Error=50.899\n",
            "Loop=2, learn_rate=0.500, Error=30.583\n",
            "Loop=3, learn_rate=0.500, Error=23.911\n",
            "Loop=4, learn_rate=0.500, Error=21.117\n",
            "Loop=5, learn_rate=0.500, Error=19.666\n",
            "Loop=6, learn_rate=0.500, Error=18.828\n",
            "Loop=7, learn_rate=0.500, Error=18.297\n",
            "Loop=8, learn_rate=0.500, Error=17.936\n",
            "Loop=9, learn_rate=0.500, Error=17.681\n",
            "Loop=10, learn_rate=0.500, Error=17.497\n",
            "Loop=11, learn_rate=0.500, Error=17.362\n",
            "Loop=12, learn_rate=0.500, Error=17.258\n",
            "Loop=13, learn_rate=0.500, Error=17.175\n",
            "Loop=14, learn_rate=0.500, Error=17.106\n",
            "Loop=15, learn_rate=0.500, Error=17.048\n",
            "Loop=16, learn_rate=0.500, Error=16.997\n",
            "Loop=17, learn_rate=0.500, Error=16.955\n",
            "Loop=18, learn_rate=0.500, Error=16.920\n",
            "Loop=19, learn_rate=0.500, Error=16.892\n",
            "Loop=20, learn_rate=0.500, Error=16.871\n",
            "Loop=21, learn_rate=0.500, Error=16.857\n",
            "Loop=22, learn_rate=0.500, Error=16.849\n",
            "Loop=23, learn_rate=0.500, Error=16.848\n",
            "Loop=24, learn_rate=0.500, Error=16.852\n",
            "Loop=25, learn_rate=0.500, Error=16.861\n",
            "Loop=26, learn_rate=0.500, Error=16.873\n",
            "Loop=27, learn_rate=0.500, Error=16.888\n",
            "Loop=28, learn_rate=0.500, Error=16.904\n",
            "Loop=29, learn_rate=0.500, Error=16.921\n",
            "Loop=30, learn_rate=0.500, Error=16.938\n",
            "Loop=31, learn_rate=0.500, Error=16.954\n",
            "Loop=32, learn_rate=0.500, Error=16.969\n",
            "Loop=33, learn_rate=0.500, Error=16.982\n",
            "Loop=34, learn_rate=0.500, Error=16.993\n",
            "Loop=35, learn_rate=0.500, Error=17.003\n",
            "Loop=36, learn_rate=0.500, Error=17.011\n",
            "Loop=37, learn_rate=0.500, Error=17.017\n",
            "Loop=38, learn_rate=0.500, Error=17.021\n",
            "Loop=39, learn_rate=0.500, Error=17.025\n",
            "Loop=40, learn_rate=0.500, Error=17.027\n",
            "Loop=41, learn_rate=0.500, Error=17.028\n",
            "Loop=42, learn_rate=0.500, Error=17.028\n",
            "Loop=43, learn_rate=0.500, Error=17.027\n",
            "Loop=44, learn_rate=0.500, Error=17.026\n",
            "Loop=45, learn_rate=0.500, Error=17.025\n",
            "Loop=46, learn_rate=0.500, Error=17.024\n",
            "Loop=47, learn_rate=0.500, Error=17.023\n",
            "Loop=48, learn_rate=0.500, Error=17.021\n",
            "Loop=49, learn_rate=0.500, Error=17.020\n",
            "Loop=50, learn_rate=0.500, Error=17.019\n",
            "Loop=51, learn_rate=0.500, Error=17.017\n",
            "Loop=52, learn_rate=0.500, Error=17.016\n",
            "Loop=53, learn_rate=0.500, Error=17.015\n",
            "Loop=54, learn_rate=0.500, Error=17.015\n",
            "Loop=55, learn_rate=0.500, Error=17.014\n",
            "Loop=56, learn_rate=0.500, Error=17.014\n",
            "Loop=57, learn_rate=0.500, Error=17.013\n",
            "Loop=58, learn_rate=0.500, Error=17.013\n",
            "Loop=59, learn_rate=0.500, Error=17.012\n",
            "Loop=60, learn_rate=0.500, Error=17.012\n",
            "Loop=61, learn_rate=0.500, Error=17.012\n",
            "Loop=62, learn_rate=0.500, Error=17.012\n",
            "Loop=63, learn_rate=0.500, Error=17.012\n",
            "Loop=64, learn_rate=0.500, Error=17.012\n",
            "Loop=65, learn_rate=0.500, Error=17.012\n",
            "Loop=66, learn_rate=0.500, Error=17.011\n",
            "Loop=67, learn_rate=0.500, Error=17.011\n",
            "Loop=68, learn_rate=0.500, Error=17.011\n",
            "Loop=69, learn_rate=0.500, Error=17.011\n",
            "Loop=70, learn_rate=0.500, Error=17.011\n",
            "Loop=71, learn_rate=0.500, Error=17.011\n",
            "Loop=72, learn_rate=0.500, Error=17.011\n",
            "Loop=73, learn_rate=0.500, Error=17.011\n",
            "Loop=74, learn_rate=0.500, Error=17.010\n",
            "Loop=75, learn_rate=0.500, Error=17.010\n",
            "Loop=76, learn_rate=0.500, Error=17.010\n",
            "Loop=77, learn_rate=0.500, Error=17.010\n",
            "Loop=78, learn_rate=0.500, Error=17.009\n",
            "Loop=79, learn_rate=0.500, Error=17.009\n",
            "Loop=80, learn_rate=0.500, Error=17.009\n",
            "Loop=81, learn_rate=0.500, Error=17.008\n",
            "Loop=82, learn_rate=0.500, Error=17.008\n",
            "Loop=83, learn_rate=0.500, Error=17.008\n",
            "Loop=84, learn_rate=0.500, Error=17.007\n",
            "Loop=85, learn_rate=0.500, Error=17.007\n",
            "Loop=86, learn_rate=0.500, Error=17.006\n",
            "Loop=87, learn_rate=0.500, Error=17.006\n",
            "Loop=88, learn_rate=0.500, Error=17.005\n",
            "Loop=89, learn_rate=0.500, Error=17.005\n",
            "Loop=90, learn_rate=0.500, Error=17.004\n",
            "Loop=91, learn_rate=0.500, Error=17.004\n",
            "Loop=92, learn_rate=0.500, Error=17.003\n",
            "Loop=93, learn_rate=0.500, Error=17.003\n",
            "Loop=94, learn_rate=0.500, Error=17.002\n",
            "Loop=95, learn_rate=0.500, Error=17.001\n",
            "Loop=96, learn_rate=0.500, Error=17.001\n",
            "Loop=97, learn_rate=0.500, Error=17.000\n",
            "Loop=98, learn_rate=0.500, Error=16.999\n",
            "Loop=99, learn_rate=0.500, Error=16.999\n",
            "[{'weights': [7.437407421046006, 1.2377851281945986, 0.783680853775058, 2.229245956681794, -4.400657895182286], 'output': 1.391152553522192e-07, 'delta': -5.754894889381041e-09}]\n",
            "[{'weights': [-6.190919812914874, 2.7601412907671743], 'output': 0.9403899057352816, 'delta': 0.003341547014698821}, {'weights': [6.191362374112705, -2.760357034135965], 'output': 0.05959796465206937, 'delta': -0.0033402303435731296}]\n",
            "\n",
            "TEST DATASET\n",
            "Confusion Matrix is:  [[30  0]\n",
            " [ 1 19]]\n",
            "Accuracy is:  0.98\n",
            "Precision is:  1.0\n",
            "recall is:  0.95\n",
            "\n",
            "TRAIN DATASET\n",
            "Confusion Matrix is:  [[64  5]\n",
            " [ 5 76]]\n",
            "Accuracy is:  0.9333333333333333\n",
            "Precision is:  0.9382716049382716\n",
            "recall is:  0.9382716049382716\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
